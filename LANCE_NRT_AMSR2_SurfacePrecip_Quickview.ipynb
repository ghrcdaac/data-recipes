{"cells":[{"cell_type":"markdown","metadata":{},"source":["<br>\n","LANCE NRT AMSR2 Ocean Rain Data Quickview<br>\n","<br>\n","Description: This code reads latitudes, longitudes, and surface<br>\n","precipitation rates from a LANCE NRT AMSR2 Ocean Rain Data file (*.he5)<br>\n","and generate a CSV file with these info. The CSV file will be used to<br>\n","plot surface precipitation rates in ESRI ArcMap.<br>\n","<br>\n","Authors: Lucy Wang, Leigh Sinclair,<br>\n","Information and Technology Systems Center (ITSC)<br>\n","University of Alabama in Huntsville<br>\n","<br>\n","Last Edit Date: 31 January 2019<br>\n","<br>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import tables\n","import csv"]},{"cell_type":"markdown","metadata":{},"source":["Define the file directories"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataDir = 'C:/users/lwang/documents/projects/AMSR2_DataRecipe/'\n","files = ['AMSR_2_L2_RainOcean_R00_201812312341_D.he5']\n","datafiles = [dataDir + x for x in files]"]},{"cell_type":"markdown","metadata":{},"source":["Create a list of dictionaries 'dict_list'; each dictionary has three keys 'lon', 'lat', 'sfc_precip'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dict_list = []\n","fieldnames = ['lon','lat','sfc_precip']"]},{"cell_type":"markdown","metadata":{},"source":["Loop through list of HDF-EOS5 files, for each file, extract the surface precipitation<br>\n","and correspoinding latitude and longitude "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i in datafiles:\n","    #Open HDF5 file\n","    h5file = tables.open_file(i)\n","\n","    #Read data layer(s) of interest within HDF-EOS5 file\n","    surface_precip = h5file.get_node('/HDFEOS/SWATHS/GPROF2010V2/Data Fields/surfacePrecipitation').read()\n","    quality_flag = h5file.get_node('/HDFEOS/SWATHS/GPROF2010V2/Data Fields/QualityFlag').read()\n","    pixel_status = h5file.get_node('/HDFEOS/SWATHS/GPROF2010V2/Data Fields/pixelStatus').read()\n","    lat = h5file.get_node('/HDFEOS/SWATHS/GPROF2010V2/Geolocation Fields/Latitude').read()\n","    lon = h5file.get_node('/HDFEOS/SWATHS/GPROF2010V2/Geolocation Fields/Longitude').read()\n","\n","    #Close HDF5 file\n","    h5file.close()\n","    n_track = surface_precip.shape[0]\n","    n_xtrack = surface_precip.shape[1]\n","    for ii in range(0,n_track):\n","        for jj in range(0,n_xtrack):\n","            if pixel_status[ii,jj] == 0 and quality_flag[ii,jj] == 0 and surface_precip[ii,jj] > 0:\n","               #Create a new dictionary with the three keys 'lon', 'lat', 'sfc_precip'\n","               row_dict = {}\n","               row_dict.update({'lon':lon[ii,jj],'lat':lat[ii,jj],'sfc_precip':surface_precip[ii,jj]})\n","               #Add this new dictionary to the list\n","               dict_list.append(row_dict)"]},{"cell_type":"markdown","metadata":{},"source":["Write lon, lat, surface_precip into a CSV file"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if len(dict_list) > 0:\n","   output_csv_file = dataDir + 'AMSR2_NRT_L2B_swath_20181231.csv'\n","   \n","   with open(output_csv_file,'wb') as csvfile:\n","        writer = csv.DictWriter(csvfile,fieldnames = fieldnames)\n","        writer.writeheader()\n","        writer.writerows(dict_list)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":2}
