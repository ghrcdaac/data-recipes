{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# -*- coding: utf-8 -*-"]},{"cell_type":"markdown","metadata":{},"source":["<br>\n","       OTD Lightning Flash Heat Map and Flash Location <br>\n","       CSV File<br>\n","<br>\n","       Decription: This code pulls OTD HDF data files <br>\n","       from a directory, decompressed the files, extracts the <br>\n","       flash coordinates from the files and generates a flash <br>\n","       heat map plot. This code also compiles all lightning <br>\n","       flash locations into a single CSV file, so they may <br>\n","       be plotted using other software.<br>\n","<br>\n","       Authors: Amanda Markert and Essence Raphael<br>\n","       Information and Technology Systems Center (ITSC)<br>\n","       University of Alabama in Huntsville<br>\n","       <br>\n","       Last Edit Date: 17 October 2019<br>\n","<br>\n","\n","Import Python Packages"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: matplotlib in /home/davis_dev/anaconda3/lib/python3.9/site-packages (3.5.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /home/davis_dev/anaconda3/lib/python3.9/site-packages (from matplotlib) (4.25.0)\n","Requirement already satisfied: pyparsing>=2.2.1 in /home/davis_dev/anaconda3/lib/python3.9/site-packages (from matplotlib) (3.0.4)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /home/davis_dev/anaconda3/lib/python3.9/site-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /home/davis_dev/anaconda3/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: packaging>=20.0 in /home/davis_dev/anaconda3/lib/python3.9/site-packages (from matplotlib) (21.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /home/davis_dev/anaconda3/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: pillow>=6.2.0 in /home/davis_dev/anaconda3/lib/python3.9/site-packages (from matplotlib) (9.0.1)\n","Requirement already satisfied: numpy>=1.17 in /home/davis_dev/anaconda3/lib/python3.9/site-packages (from matplotlib) (1.21.5)\n","Requirement already satisfied: six>=1.5 in /home/davis_dev/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Requirement already satisfied: Cartopy in /home/davis_dev/anaconda3/lib/python3.9/site-packages (0.18.0)\n","Requirement already satisfied: six>=1.3.0 in /home/davis_dev/anaconda3/lib/python3.9/site-packages (from Cartopy) (1.16.0)\n","Requirement already satisfied: setuptools>=0.7.2 in /home/davis_dev/anaconda3/lib/python3.9/site-packages (from Cartopy) (61.2.0)\n","Requirement already satisfied: pyshp>=1.1.4 in /home/davis_dev/anaconda3/lib/python3.9/site-packages (from Cartopy) (2.1.3)\n","Requirement already satisfied: shapely>=1.5.6 in /home/davis_dev/anaconda3/lib/python3.9/site-packages (from Cartopy) (1.7.1)\n","Requirement already satisfied: numpy>=1.10 in /home/davis_dev/anaconda3/lib/python3.9/site-packages (from Cartopy) (1.21.5)\n","Requirement already satisfied: numpy in /home/davis_dev/anaconda3/lib/python3.9/site-packages (1.21.5)\n","Requirement already satisfied: pyhdf in /home/davis_dev/anaconda3/lib/python3.9/site-packages (0.10.5)\n","Requirement already satisfied: numpy in /home/davis_dev/anaconda3/lib/python3.9/site-packages (from pyhdf) (1.21.5)\n"]},{"ename":"RuntimeError","evalue":"module compiled against API version 0xf but this version of numpy is 0xe","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"]},{"ename":"SystemError","evalue":"initialization of _hdfext raised unreported exception","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)","\u001b[1;32m/home/davis_dev/github/data-recipes/OTD_FlashLoc_Quickview.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/davis_dev/github/data-recipes/OTD_FlashLoc_Quickview.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msubprocess\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/davis_dev/github/data-recipes/OTD_FlashLoc_Quickview.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/davis_dev/github/data-recipes/OTD_FlashLoc_Quickview.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyhdf\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mHDF\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/davis_dev/github/data-recipes/OTD_FlashLoc_Quickview.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyhdf\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mVS\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/davis_dev/github/data-recipes/OTD_FlashLoc_Quickview.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pyhdf/HDF.py:73\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39mBasic API (:mod:`pyhdf.HDF`)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m============================\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39msys\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mtypes\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m hdfext \u001b[39mas\u001b[39;00m _C\n\u001b[1;32m     74\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39msix\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmoves\u001b[39;00m \u001b[39mimport\u001b[39;00m xrange\n\u001b[1;32m     75\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mHC\u001b[39;00m \u001b[39mimport\u001b[39;00m HC\n","File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pyhdf/hdfext.py:17\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m             \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39m'\u001b[39m\u001b[39m_hdfext\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m     _hdfext \u001b[39m=\u001b[39m swig_import_helper()\n\u001b[1;32m     18\u001b[0m     \u001b[39mdel\u001b[39;00m swig_import_helper\n\u001b[1;32m     19\u001b[0m \u001b[39melif\u001b[39;00m _swig_python_version_info \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m2\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m0\u001b[39m):\n","File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pyhdf/hdfext.py:14\u001b[0m, in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m mname \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin((pkg, \u001b[39m'\u001b[39m\u001b[39m_hdfext\u001b[39m\u001b[39m'\u001b[39m))\u001b[39m.\u001b[39mlstrip(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39;49mimport_module(mname)\n\u001b[1;32m     15\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39m'\u001b[39m\u001b[39m_hdfext\u001b[39m\u001b[39m'\u001b[39m)\n","File \u001b[0;32m~/anaconda3/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n","\u001b[0;31mSystemError\u001b[0m: initialization of _hdfext raised unreported exception"]}],"source":["! pip install matplotlib\n","! pip install Cartopy\n","! pip install numpy\n","! pip install pyhdf\n","\n","import sys\n","import glob\n","import os\n","import tarfile\n","import subprocess\n","import re\n","from pyhdf.HDF import *\n","from pyhdf.VS import *\n","import numpy as np\n","import datetime\n","import csv\n","import matplotlib.pyplot as plt\n","import cartopy.crs as ccrs\n","import cartopy.feature as cfeature\n","import matplotlib.ticker as mticker\n","from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n","\n","# Initial file path. It can be changed by passing a different path as an argument\n","# to the main() function\n","\n","file_path = 'D:/data_recipes/otd/'\n","\n","def main(file_path):\n","\n","    #Define the data directoy and identify the .tar files inside the data directory\n","    dataDir = os.path.join(file_path, '')\n","    raw_tar_files = glob.glob(dataDir+'otdlip_*_daily.tar')\n","    tfiles = [os.path.normpath(i) for i in raw_tar_files]\n","\n","    #Extract earliest and latest dates from \"tfiles\" to create directory names\n","    #Create empty list to hold dates and loop through each .tar to extract the date from its filename\n","    file_dates = []\n","    for i in tfiles:\n","        file_dates.append(re.findall('(\\d+\\.\\d+)', i))\n","    \n","    #Select the maximum and minimum dates\n","    file_dates_start = min(file_dates)\n","    file_dates_end = max(file_dates)\n","\n","    #Create a new folder to hold the untarred data files; a different folder title is given based on whether the data\n","    #covers a single date or multiple dates\n","    if file_dates_start != file_dates_end:\n","        os.mkdir(os.path.normpath(dataDir+'otd_' + file_dates_start[0] + '_' + file_dates_end[0] + '_untarred_daily'))\n","        untar_dataDir = os.path.join(file_path, 'otd_' + file_dates_start[0] + '_' + file_dates_end[0] + '_untarred_daily/')\n","    else:\n","        os.mkdir(os.path.normpath(dataDir+'otd_' + file_dates_start[0] + '_untarred_daily'))\n","        untar_dataDir = os.path.join(file_path, 'otd_' + file_dates_start[0] + '_untarred_daily/')\n","\n","    #Untar and extract all files contained within each .tar file\n","    for i in tfiles:\n","        with tarfile.TarFile(i, 'r') as tar_files:\n","            tar_files.extractall(untar_dataDir)\n","\n","    #Identify the .Z files inside the untarred files data directory\n","    raw_untarred_files = glob.glob(untar_dataDir+'mlab.otd.1_1.*Z')\n","    untarred_files = [os.path.normpath(i) for i in raw_untarred_files]\n","\n","    #Identify the path to 7z application file, use 7-Zip to decompress the .Z files, identify the target directory for \n","    #the unzipped files, and delete the .Z files after extraction\n","    for i in untarred_files:\n","        z_location = 'C:/Program Files/7-Zip/7z.exe'\n","        subprocess.call(z_location+' x '+i+' -o'+untar_dataDir)\n","        os.remove(i)\n","\n","    #Identify the OTD HDF files in the directory\n","    raw_files = glob.glob(untar_dataDir+'mlab.otd.1_1.*')\n","    files = [os.path.normpath(i) for i in raw_files]\n","\n","    #Create empty numpy arrays to hold the flash latitudes, longitudes, and occurence times\n","    flash_lats = np.array([])\n","    flash_lons = np.array([])\n","    times = np.array([])\n","\n","    #Loop through and read each OTD HDF file\n","    for i in files:\n","        vs_file = HDF(i, HC.READ).vstart()\n","        \n","        #Define the location of the lightning flash coordinates in the HDF files using reference numbers \n","        flash_flash = vs_file.attach(14)\n","\n","        #Store the number of flash records in a variable to use when reading the data from the\n","        #HDF file\n","        flash_inquire = flash_flash.inquire()\n","        record_count = flash_inquire[0]\n","\n","        #Create a numpy array of the flash records that have been read \n","        flash_records = flash_flash.read(record_count)\n","\n","        #Loop through each flash record. Extract the latitude, longitude, and occurence time for each \n","        #flash. For each flash, add its latitude, longitude, and occurence time to the \"flash_lats\",\n","        #\"flash_lons\", and \"times\" respectively.\n","        for i in flash_records:\n","            flash_lats = np.concatenate((flash_lats, i[8][0]), axis=None)\n","            flash_lons = np.concatenate((flash_lons, i[8][1]), axis=None)\n","            times = np.concatenate((times, i[1]), axis=None)\n","\n","    #This section extracts and formats the flash occurence times\n","    #Identify the earliest and latest flash timestamps in the \"times\" array\n","    start_seconds = min(times)\n","    end_seconds = max(times)\n","\n","    #Define the units for the start and end times then convert these times \n","    #(seconds since 1993-01-01 00:00:00.000) to dates\n","    x = datetime.datetime(1993,1,1)\n","    start_date = x + datetime.timedelta(seconds=start_seconds)\n","    end_date = x + datetime.timedelta(seconds=end_seconds)\n","\n","    #Create numerical and text date & time strings to use in filenames and the flash heat map title\n","    start_date_txt = start_date.strftime(\"%B %d, %Y\")\n","    end_date_txt = end_date.strftime(\"%B %d, %Y\")\n","    start_int = start_date.strftime(\"%Y%m%d\")\n","    end_int = end_date.strftime(\"%Y%m%d\")\n","    start_time = start_date.strftime(\"%X\")\n","    end_time = end_date.strftime(\"%X\")\n","\n","    #Create CSV file and destination; a different title is given based on whether the data\n","    #covers a single date or multiple dates\n","    if start_int != end_int:\n","        csvfile = os.path.join(dataDir, 'otd_'+ start_int + '_' + end_int + '_flashloc.csv')\n","    else:\n","        csvfile = os.path.join(dataDir, 'otd_'+ start_int + '_flashloc.csv')\n","\n","    #Create csv file\n","    with open(csvfile, 'w', newline='') as myfile:\n","        writer = csv.writer(myfile)\n","        writer.writerows(zip([\"flash_lat\"], [\"flash_lon\"])) #Define headers in row (zip creates columns)\n","        writer.writerows(zip(flash_lats,flash_lons)) #Define data rows (zip creates columns)\n","\n","    #Create plot of lightning flash location heat map\n","    plt.figure(figsize=((20,20))) #Set plot dimensions\n","    map = plt.axes(projection=ccrs.PlateCarree(central_longitude=0.0))\n","    gl = map.gridlines(crs=ccrs.PlateCarree(central_longitude=0.0), draw_labels=True, linewidth=0.8, alpha=0.5, color='white', linestyle='--')\n","    lightning = map.hexbin(flash_lons, flash_lats, gridsize=300, bins='log',cmap='jet', mincnt=1 ,zorder=10) #Bin flash counts into hexbins using a gridsize of your choice\n","\n","    #Draw geographic boundaries and meridians/parallels\n","    map.set_extent([-180, 180,-90, 90])\n","    map.coastlines(color='white')\n","    map.add_feature(cfeature.LAND, facecolor='gray')\n","    map.add_feature(cfeature.BORDERS, edgecolor='white')\n","    map.add_feature(cfeature.OCEAN, facecolor='black')\n","    gl.ylocator = mticker.FixedLocator([-90, -60, -30, 0 ,30, 60, 90])\n","    gl.xlocator = mticker.FixedLocator([-180, -150, -120, -90, -60, -30, 0 ,30, 60, 90, 120, 150, 180])\n","    gl.xformatter = LONGITUDE_FORMATTER\n","    gl.yformatter = LATITUDE_FORMATTER\n","    gl.xlabels_top=False\n","    gl.ylabels_right=False\n","    \n","    #Create colorbar\n","    cbar = plt.colorbar(lightning, orientation='horizontal', pad=0.02, aspect=50) \n","    cbar.set_label('Flash Count', fontsize=12) #Remember to change label\n","        \n","    #Create plot title based on file dates and times; a different title is given based on whether the data\n","    #covers a single date or multiple dates\n","    if start_date_txt != end_date_txt:\n","        plot_title = 'OTD Detected Lightning Flash Locations ' + start_date_txt + ' ' + start_time + ' - ' + end_date_txt + ' ' + end_time\n","        plt.title(plot_title, fontsize = 18)\n","        \n","        #Save the plot as an image\n","        plt.savefig(os.path.join(dataDir, 'otd_' + start_int + '_' + end_int +'_flashloc_plot.png'), bbox_inches='tight') \n","        \n","    else:\n","        plot_title = 'OTD Detected Lightning Flash Locations ' + end_date_txt + ' ' + start_time + ' - ' + end_time\n","        plt.title(plot_title, fontsize = 18) \n","   \n","        #Save the plot as an image\n","        plt.savefig(os.path.join(dataDir, 'otd_' + start_int +'_flashloc_plot.png'), bbox_inches='tight')  \n","if __name__ == \"__main__\":\n","    if len(sys.argv) > 1:\n","        file_path = sys.argv[1]\n","        main(file_path)\n","    else:\n","        main(file_path)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"a095a0f487344c688288b7e5a6e0064de8ffe78aee5a45c461691f60996a49b8"}}},"nbformat":4,"nbformat_minor":2}
